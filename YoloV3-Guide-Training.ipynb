{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Box Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b_x=\\sigma(t_x)+c_x$  \n",
    "\n",
    "$b_y=\\sigma(t_y)+c_y$  \n",
    "\n",
    "$b_\\omega=p_\\omega e^{t_\\omega}$  \n",
    "\n",
    "$b_h=p_h e^{t_h}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/bb-predictions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv3 predicts an objectness score for each bounding box using logistic regression. \n",
    "* This should be 1 if the bounding box prior overlaps a ground truth object.\n",
    "* If bounding box prior is not the best but does overlap a ground truth object by more than some threshold,ignore the prediction.\n",
    "* if a bounding box prior is not assigned to a ground truth object and not ignored it incurs no loss for coordinate or class predictions, only objectness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/darknet53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict bounding boxes across different feature maps scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5 max poolings, for default input size (416,416) this is (13,13)\n",
    "* 4 max poolings, for default input size (416,416) this is (26,26)\n",
    "* 3 max poolings, for default input size (416,416) this is (52,52)\n",
    "* For default input image size (416,416), there are $(13\\times13+26\\times26+52\\times52)\\times num\\_anchors$ bounding box detectors in YOLOV3. \n",
    "* The smaller feature maps （with larger receptive field） usually predicts bounding boxes refers to big anchors\n",
    "* The YOLOv3 upsamples the final feature maps (13,13) to (26,26) and (52,52), and concatenates them with feature maps of shadow convolutional layers(contains more detail features) to predict small objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolo loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(b1,b2):\n",
    "    '''Return iou tensor\n",
    "    This function is later used in yolo_loss function to decide which bounding box detectors can be ignored\n",
    "    Parameters\n",
    "    b1:tensor,shape=(i1,...,iN,4) xywh\n",
    "    b2:tensor,shape=(j,4),xywh\n",
    "    '''\n",
    "    #  Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(axis=-2) #(i1,...,iN,1,4)\n",
    "    b1_xy = b1[...,0:2]\n",
    "    b1_wh = b1[...,2:4] \n",
    "    b1_wh_half = b1_wh/2.0 \n",
    "    b1_mins = b1_xy-b1_wh_half #(i1,...,iN,1,2)\n",
    "    b1_maxes = b1_xy+b1_wh_half #(i1,...,iN,1,2)\n",
    "\n",
    "    b2_xy = b2[...,0:2] #(j,2)\n",
    "    b2_wh = b2[...,2:4]\n",
    "    b2_wh_half = b2_wh/2.0 \n",
    "    b2_mins = b2_xy-b2_wh_half #(j,2)\n",
    "    b2_maxes = b2_xy+b2_wh_half #(j,2)\n",
    " \n",
    "    intersect_mins = K.maximum(b1_mins,b2_mins) #(i1,...,iN,j,2)\n",
    "    intersect_maxes = K.minimum(b1_maxes,b2_maxes) #(i1,...,iN,j,2)\n",
    "    intersect_wh = K.maximum(intersect_maxes-intersect_mins,0) #(i1,...,iN,j,2)\n",
    "    intersect_area = intersect_wh[...,0]*intersect_wh[...,1] #(i1,...,iN,j)\n",
    "    b1_area = b1_wh[...,0]*b1_wh[...,1] #(i1,...,iN,j)\n",
    "    b2_area = b2_wh[...,0]*b2_wh[...,1] #(i1,...,iN,j)\n",
    "    iou = intersect_area/(b1_area+b2_area-intersect_area) #(i1,...,iN,j)\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(args,anchors,num_classes,ignore_thresh=0.5):\n",
    "    '''\n",
    "        yolo_outputs:list of tensor, the output of three different convolutional layer of yolo_body,\n",
    "        shape=[batch_size,grid_h,grid_w,num_anchors,(5+num_classes)] (the xywh are relative value calculate by the equations above).\n",
    "        \n",
    "        y_true: list of tensors represent the true value, shape = [batch_size,grid_h,grid_w,num_anchors,5+num_classes] \n",
    "        (the xywh are normalized by the size of input image).\n",
    "        \n",
    "        anchors:2-dims array,shape=(N,2) \n",
    "        \n",
    "        num_classes:integer\n",
    "        \n",
    "        ignore_thres:float, the iou threshold whether to ignore object confidence loss\n",
    "    '''\n",
    "    num_layers = len(anchors)//3\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_trues = args[num_layers:] \n",
    "    anchor_masks = [[6,7,8],[3,4,5],[0,1,2]] if num_layers==3 else [[3,4,5],[1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3]*32,dtype=K.dtype(y_true[0]))\n",
    "    loss = 0\n",
    "    \n",
    "    for l in range(num_layers):\n",
    "        \n",
    "        m = K.shape(yolo_outputs[l])[0]\n",
    "        mf = K.cast(m,K.dtype(yolo_outputs[l]))\n",
    "        yolo_output = yolo_outputs[l] # [batch_size,grid_h,grid_w,num_anchors*(5+num_classes)]\n",
    "        y_true = y_trues[l] # [batch_size,grid_h,grid_w,num_anchor,5+num_classes]\n",
    "        \n",
    "        grid_shape = K.cast(K.shape(yolo_output)[1:3],dtype=K.dtype(y_true[0])) # (2,)\n",
    "        grid_h,gird_w = grid_shape[0],grid_shape[1]\n",
    "        \n",
    "        anchors_data = anchors[anchor_masks[l]]\n",
    "        num_anchors  len(anchors_data)\n",
    "        anchors_tensor = K.reshape(K.constant(anchors_data),shape=[1,1,1,num_anchors,2]) # [1,1,1,num_anchors,2]\n",
    "        \n",
    "        raw_pred = K.reshape(yolo_output,shape=[m,grid_h,grid_w,num_anchors,5+num_classes]) # [batch_size,grid_h,grid_w,num_anchors,5+num_classes]\n",
    "        object_mask = y_true[...,4:5] # [batch_size,grid_h,grid_w,num_anchors,1]\n",
    "        \n",
    "        # calculate the xywh loss\n",
    "        # ** Frist generate the offset matrics, think about the np.meshgrid to understant the following code\n",
    "        grid_y = K.arange(0,grid_h) #(grid_h,)\n",
    "        grid_y = K.expand_dims(grid_y,axis=1) #(gird_h,1)\n",
    "        grid_y = K.tile(grid_y,[1,grid_w]) #(grid_h,gird_w)\n",
    "        grid_x = K.arange(0,grid_w) #(grid_w,)\n",
    "        grid_x = K.expand_dims(grid_x,axis=0) #(1,grid_w)\n",
    "        grid_x = K.tile(grid_x,[grid_h,1]) #(grid_h,grid_w)\n",
    "        grid = K.stack([grid_x,grid_y],axis=2) #(grid_h,grid_w,2)\n",
    "        grid = K.expand_dims(grid,axis=-2) #(grid_h,grid_w,1,2)\n",
    "        grid = K.expand_dims(grid,axis=0) #(1,grid_h,grid_w,1,2) \n",
    "        # ** Second reshape the yolo_outputs to [batch_size,grid_h,grid_w,num_anchors,5+num_classes]\n",
    "        # ** and normalize the bounding box parameters of the y_true as the equation above\n",
    "        raw_true_xy = y_true[...,:2]*grid_shape[::-1]-grid #[batch_size,grid_h,grid_w,num_anchors,2]\n",
    "        raw_true_wh = K.log(y_true[...,2:4]*input_shape[::-1]/anchors_tensor) #[batch_size,grid_h,grid_w,num_anchors,2]\n",
    "        raw_true_wh = K.switch(object_mask,raw_true_wh,K.zeros_like(raw_true_wh))# [batch_size,grid_h,grid_w,num_anchors,2] (prevent log0)\n",
    "        box_loss_scale = 1+(1-y_true[...,2:3]*y_true[l][...,3:4]) # [batch_size,grid_h,grid_w,num_anchors,1]\n",
    "        # ** calculate the xywh loss\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy,raw_pred[...,0:2],from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        xy_loss = K.sum(xy_loss)/mf\n",
    "        wh_loss = K.sum(wh_loss)/mf\n",
    "        loss +=xy_loss\n",
    "        loss +=wh_loss        \n",
    "        \n",
    "                \n",
    "        # calculate the confidence loss\n",
    "        # ** First,calculate the iou between all the predicted bounding boxes and all the ground truth boxes, \n",
    "        # ** and for a predicted box that is not responsible for predicting any ground truth boxes,\n",
    "        # ** if the predicted bounding box does overlap a ground truth object by more than a threashold, \n",
    "        # ** the predicted box should be ignored when calculate the confidence loss.s        \n",
    "        pred_xy = (K.sigmoid(raw_pred[...,0:2])+grid)/K.cast(grid_shape[::-1],K.dtype(feats)) # [batch_size,grid_h,grid_w,num_anchors,2]\n",
    "        pred_wh = K.exp(raw_pred[...,2:4])*anchors_tensor/K.cast(input_shape[::-1,K.dtype(feats)]) # [batch_size,grid_h,grid_w,num_anchors,2]\n",
    "        pred_box = K.concatenate([pred_xy,pred_wh],axis=-1) # [batch_size,grid_h,grid_w,num_anchors,4]       \n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]),size=1,dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask,'bool')\n",
    "        def loop_body(b,ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[b,...,0:4],object_mask_bool[b,...,0]) # [j,4]\n",
    "            iou = box_iou(pred_box[b,...,0:4],true_box)# [grid_h,grid_w,num_anchors,j]\n",
    "            best_iou = K.max(iou,axis=-1) #[grid_h,grid_w,num_anchors]\n",
    "            ignore_mask = ignore_mask.write(b,K.cast(best_iou<ignore_thresh,K.dtype(true_box)))#list of tensor-[grid_y,grid_x,num_anchors]\n",
    "            return b+1,ignore_mask\n",
    "        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])#list of tensor-[grid_y,grid_x,num_anchors]\n",
    "        ignore_mask = ignore_mask.stack(axis=0)#[batch_size,grid_y,grid_x,num_anchors]\n",
    "        ignore_mask = K.expand_dims(ignore_mask,axis=-1) #[batch_size,grid_y,grid_x,num_anchors,1]\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "        (1-object_mask) * ignore_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) \n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        loss += confidence_loss\n",
    "        \n",
    "        # calculate the class loss\n",
    "        class_loss = object_mask*K.binary_crossentropy(true_class_probs,raw_pred[...,5:],from_logits=True)\n",
    "        class_loss = K.sum(class_loss)/mf\n",
    "        loss += class_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv3 Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from yolov3_body import YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model,num_layers=185):\n",
    "    '''\n",
    "        185:for the darknet body\n",
    "        -3:for the three prediction layer\n",
    "    '''\n",
    "    num_layers = num_layers if num_layers > 0 else len(model.layers)+num_layers\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainabel = i < num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (416,416)\n",
    "anchor_path = 'model_data/yolo_anchors.txt'\n",
    "classes_path = 'model_data/classes.txt'\n",
    "weights_path = 'model_data/yolo.h5'\n",
    "yolov3 = YOLOv3(input_shape,anchor_path,classes_path,weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
