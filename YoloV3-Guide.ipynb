{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Box Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b_x=\\sigma(t_x)+c_x$  \n",
    "\n",
    "$b_y=\\sigma(t_y)+c_y$  \n",
    "\n",
    "$b_\\omega=p_\\omega e^{t_\\omega}$  \n",
    "\n",
    "$b_h=p_h e^{t_h}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/bb-predictions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv3 predicts an objectness score for each bounding box using logistic regression. \n",
    "* This should be 1 if the bounding box prior overlaps a ground truth object.\n",
    "* If bounding box prior is not the best but does overlap a ground truth object by more than some threshold,ignore the prediction.\n",
    "* if a bounding box prior is not assigned to a ground truth object and not ignored it incurs no loss for coordinate or class predictions, only objectness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/darknet53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict bounding boxes across different feature maps scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5 max poolings, for default input size (416,416) this is (13,13)\n",
    "* 4 max poolings, for default input size (416,416) this is (26,26)\n",
    "* 3 max poolings, for default input size (416,416) this is (52,52)\n",
    "* For default input image size (416,416), there are $(13\\times13+26\\times26+52\\times52)\\times num\\_anchors$ bounding box detectors in YOLOV3. \n",
    "* The smaller feature maps （with larger receptive field） usually predicts bounding boxes refers to big anchors\n",
    "* The YOLOv3 upsamples the final feature maps (13,13) to (26,26) and (52,52), and concatenates them with feature maps of shadow convolutional layers(contains more detail features) to predict small objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from yolov3_body import yolo_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolo loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_head(feats,anchors,num_classes,input_shape):\n",
    "    '''\n",
    "    This function convert the feature maps of three different convolutional layer of yolov3_body to bounding box parameters.\n",
    "    The transformation of bounding box are shown in above picture\n",
    "    feats:       4-dims tensor, shape = (m,grid_h,grid_w,num_anchors*(5+num_classes))\n",
    "    anchors:     2-dims array,  shape = (num_anchors,2)\n",
    "    input_shape: 2-dims tensor, shape = (2,)\n",
    "    '''\n",
    "    \n",
    "    num_anchors = len(anchors)\n",
    "    grid_shape = K.shape(feats)[1:3]\n",
    "    \n",
    "    # This is for broadcasting -> (batch_size, height, width, num_anchors, box_params)\n",
    "    anchors_tensor = K.reshape(K.constant(anchors),shape=[1,1,1,num_anchors,2])\n",
    "    feats = K.reshape(feats,[-1,grid_shape[0],grid_shape[1],num_anchors,num_classes+5])\n",
    "    \n",
    "    # Create the Offset matrics\n",
    "    # Consider the np.meshgrid to understand the following code\n",
    "    grid_y = K.arange(0,grid_shape[0])\n",
    "    grid_y = K.expand_dims(grid_y,axis=1)\n",
    "    grid_y = K.tile(grid_y,[1,grid_shape[1]])\n",
    "    \n",
    "    grid_x = K.arange(0,grid_shape[1])\n",
    "    grid_x = K.expand_dims(grid_x,axis=[0])\n",
    "    grid_x = K.tile(grid_y,[grid_shape[0],1])\n",
    "    \n",
    "    grid = K.stack([grid_x,grid_y],axis=-1)\n",
    "    grid = K.expand_dims(grid_x,axis=2) # This is for broadcasting\n",
    "    grid = K.expand_dims(grid_x,axis=0) # This is for broadcasting\n",
    "    grid = K.cast(grid,K.dtype(feats))\n",
    "    \n",
    "    # apply the Offset matrics to the feats\n",
    "    box_xy = (K.sigmoid(feats[...,:2])+grid)/K.cast(grid_shape[::-1],K.dtype(feats))\n",
    "    box_wh = K.exp(feats[...,2:4])*anchors_tensor/K.cast(input_shape[::-1,K.dtype(feats)])\n",
    "    \n",
    "    return grid, feats, box_xy, box_wh\n",
    "\n",
    "def box_iou(b1,b2):\n",
    "    '''Return iou tensor\n",
    "    This function is later used in yolo_loss function to decide which bounding box detectors can be ignored\n",
    "    Parameters\n",
    "    b1:tensor,shape=(i1,...,iN,4) xywh\n",
    "    b2:tensor,shape=(j,4),xywh\n",
    "    '''\n",
    "    #  Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(axis=-2)\n",
    "    b1_xy = b1[...,0:2]\n",
    "    b1_wh = b1[...,2:4]\n",
    "    b1_wh_half = b1_wh/2.0\n",
    "    b1_mins = b1_xy-b1_wh_half\n",
    "    b1_maxes = b1_xy+b1_wh_half\n",
    "\n",
    "    b2_xy = b2[...,0:2]\n",
    "    b2_wh = b2[...,2:4]\n",
    "    b2_wh_half = b2_wh/2.0\n",
    "    b2_mins = b2_xy-b2_wh_half\n",
    "    b2_maxes = b2_xy+b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins,b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes,b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes-intersect_mins,0)\n",
    "    intersect_area = intersect_wh[...,0]*intersect_wh[...,1]\n",
    "    b1_area = b1_wh[...,0]*b1_wh[...,1]\n",
    "    b2_area = b2_wh[...,0]*b2_wh[...,1]\n",
    "    iou = intersect_area/(b1_area+b2_area-intersect_area)\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(args,anchors,num_classes,ignore_thresh=0.5):\n",
    "    '''\n",
    "        yolo_outputs:list of tensor, the output of three different convolutional layer of yolo_body,\n",
    "        shape=[batch_size,grid_h,grid_w,num_anchors,(5+num_classes)] (the xywh are relative value calculate by the equations above).\n",
    "        \n",
    "        y_true: list of tensors represent the true value, shape = [batch_size,grid_h,grid_w,num_anchors,5+num_classes] \n",
    "        (the xywh are normalized by the size of input image).\n",
    "        \n",
    "        anchors:2-dims array,shape=(N,2) \n",
    "        \n",
    "        num_classes:integer\n",
    "        \n",
    "        ignore_thres:float, the iou threshold whether to ignore object confidence loss\n",
    "    '''\n",
    "    num_layers = len(anchors)//3\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:] \n",
    "    anchor_mask = [[6,7,8],[3,4,5],[0,1,2]] if num_layers==3 else [[3,4,5],[1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3]*32,dtype=K.dtype(y_true[0]))\n",
    "    grid_shape = [K.cast(K.shape(yolo_outputs[l])[1:3],dtype=K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    \n",
    "    loss = 0\n",
    "    mf = K.cast(K.shape(yolo_outputs[0])[0],K.dtype(yolo_outputs[0]))\n",
    "    \n",
    "    for l in range(num_layers):\n",
    "    \n",
    "        object_mask = y_true[l][...,4:5] #[batch_size,grid_y,grid_x,num_anchors,1]\n",
    "\n",
    "        # calculate the xywh loss\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],anchors[anchor_mask[l]],input_shape)\n",
    "        raw_true_xy = y_true[l][...,:2]*grid_shape[l][::-1]-grid\n",
    "        raw_true_wh = K.log(y_true[l][...,2:4]*input_shape[::-1]/anchors[anchor_mask[l]])\n",
    "        raw_true_wh = K.switch(object_mask,raw_true_wh,K.zeros_like(raw_true_wh))\n",
    "        box_loss_scale = 1+(1-y_true[l][...,2:3]*y_true[l][...,3:4]) # better for understanding\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy,raw_pred[...,0:2],from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        xy_loss = K.sum(xy_loss)/mf\n",
    "        wh_loss = K.sum(wh_loss)/mf\n",
    "        loss +=xy_loss\n",
    "        loss +=wh_loss\n",
    "        \n",
    "        # calculate the confidence loss\n",
    "        # if the bounding box detector overlap a ground truth object by more than some threashold, \n",
    "        # the prediction should be ignored when calculate the confidence loss\n",
    "        pred_box = K.concatenate([pred_xy,pred_wh]) # used for iou calculation\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]),size=1,dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask,'bool')\n",
    "        def loop_body(b,ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4],object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b,...,0:4],true_box)#[grid_y,grid_x,num_anchors,j]\n",
    "            best_iou = K.max(iou,axis=-1) #[grid_y,grid_x,num_anchors]\n",
    "            ignore_mask = ignore_mask.write(b,K.cast(best_iou<ignore_thresh,K.dtype(true_box)))#list of tensor-[grid_y,grid_x,num_anchors]\n",
    "            return b+1,ignore_mask\n",
    "        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])#list of tensor-[grid_y,grid_x,num_anchors]\n",
    "        ignore_mask = ignore_mask.stack()#[batch_size,grid_y,grid_x,num_anchors]\n",
    "        ignore_mask = K.expand_dims(ignore_mask,axis=-1) #[batch_size,grid_y,grid_x,num_anchors,1]\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "        (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        loss += confidence_loss\n",
    "        \n",
    "        true_class_probs = y_true[l][...,5:]\n",
    "        class_loss = object_mask*K.binary_crossentropy(true_class_probs,raw_pred[...,5:],from_logits=True)\n",
    "        class_loss = K.sum(class_loss)/mf\n",
    "        loss += class_loss\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv3 Creation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
